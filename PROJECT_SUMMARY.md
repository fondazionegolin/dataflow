# DataFlow Platform - Project Summary

## ğŸ¯ Project Overview

**DataFlow Platform** is a 100% local, node-based data science application that enables users to build, execute, and share visual workflows for data analysis, transformation, visualization, and machine learningâ€”all without sending data to the cloud.

### Key Features

âœ… **100% Local Processing** - All computation happens on your machine  
âœ… **Visual Node-Based Interface** - Drag-and-drop workflow building  
âœ… **Real-Time Visualizations** - Interactive 2D/3D plots with Plotly  
âœ… **Machine Learning** - Built-in regression and classification algorithms  
âœ… **Synthetic Data Generation** - Create datasets for testing and education  
âœ… **Intelligent Caching** - Automatic result caching with incremental updates  
âœ… **Reproducible Workflows** - Seed control and workflow versioning  
âœ… **Extensible Plugin System** - Add custom nodes easily  

---

## ğŸ“ Project Structure

```
dataflow-platform/
â”œâ”€â”€ backend/                      # Python FastAPI backend
â”‚   â”œâ”€â”€ core/                     # Core execution engine
â”‚   â”‚   â”œâ”€â”€ types.py             # Type definitions
â”‚   â”‚   â”œâ”€â”€ registry.py          # Node registry
â”‚   â”‚   â”œâ”€â”€ cache.py             # Caching system
â”‚   â”‚   â””â”€â”€ executor.py          # Workflow execution engine
â”‚   â”œâ”€â”€ nodes/                    # Node implementations
â”‚   â”‚   â”œâ”€â”€ sources.py           # Data sources (CSV, synthetic)
â”‚   â”‚   â”œâ”€â”€ transform.py         # Data transformations
â”‚   â”‚   â”œâ”€â”€ visualization.py     # Plotting nodes
â”‚   â”‚   â””â”€â”€ ml.py                # Machine learning nodes
â”‚   â”œâ”€â”€ main.py                   # FastAPI application
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”‚
â”œâ”€â”€ frontend/                     # React + Tauri frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ CustomNode.tsx   # Node visualization
â”‚   â”‚   â”‚   â”œâ”€â”€ NodePalette.tsx  # Node library
â”‚   â”‚   â”‚   â”œâ”€â”€ PropertiesPanel.tsx  # Parameter editor
â”‚   â”‚   â”‚   â””â”€â”€ Toolbar.tsx      # Top toolbar
â”‚   â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â”‚   â””â”€â”€ workflowStore.ts # Zustand state management
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts           # Backend API client
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts         # TypeScript types
â”‚   â”‚   â”œâ”€â”€ App.tsx              # Main app component
â”‚   â”‚   â””â”€â”€ main.tsx             # Entry point
â”‚   â”œâ”€â”€ src-tauri/               # Tauri configuration
â”‚   â””â”€â”€ package.json             # Node dependencies
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ API.md                   # API reference
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # System architecture
â”‚   â””â”€â”€ PLUGIN_DEVELOPMENT.md    # Plugin guide
â”‚
â”œâ”€â”€ examples/                     # Example workflows
â”‚   â”œâ”€â”€ classification_example.flow.json
â”‚   â””â”€â”€ regression_example.flow.json
â”‚
â”œâ”€â”€ README.md                     # Project overview
â”œâ”€â”€ GETTING_STARTED.md           # Quick start guide
â”œâ”€â”€ start-backend.sh             # Backend startup script
â””â”€â”€ start-dev.sh                 # Full dev environment script
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- Rust (for Tauri builds)

### Installation

1. **Install Python dependencies:**
   ```bash
   cd backend
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

2. **Install Node dependencies:**
   ```bash
   cd frontend
   npm install
   ```

### Running the Application

**Option 1: Development Mode (Browser)**
```bash
# Terminal 1: Start backend
./start-backend.sh

# Terminal 2: Start frontend
cd frontend
npm run dev
```

**Option 2: Desktop App**
```bash
cd frontend
npm run tauri:dev
```

**Option 3: Quick Start**
```bash
./start-dev.sh
```

---

## ğŸ¨ Available Nodes

### ğŸ“ Data Sources
- **Load CSV** - Import CSV files with configurable parsing
- **Generate Synthetic Data** - Create datasets with various distributions and patterns

### ğŸ”§ Transform
- **Select Columns** - Choose specific columns from tables
- **Filter Rows** - Filter data using pandas query expressions
- **Transform Columns** - Scale, normalize, encode features
- **Train/Test Split** - Split datasets for machine learning
- **Drop Missing Values** - Handle NA values

### ğŸ“Š Visualization
- **2D Scatter Plot** - Interactive scatter plots with color/size mapping
- **3D Scatter Plot** - 3D visualization with rotation
- **Histogram** - Distribution analysis

### ğŸ¤– Machine Learning
- **Regression** - Linear, Ridge, Lasso, Random Forest, Gradient Boosting, SVR, KNN
- **Classification** - Logistic, Random Forest, Gradient Boosting, SVC, KNN, Naive Bayes
- **Predict** - Apply trained models to new data

---

## ğŸ—ï¸ Architecture Highlights

### Backend (Python)
- **FastAPI** for REST API
- **pandas** for data manipulation
- **scikit-learn** for machine learning
- **plotly** for visualizations
- **pyarrow** for efficient data serialization

### Frontend (TypeScript + React)
- **Tauri** for desktop application
- **React Flow** for node-based canvas
- **Zustand** for state management
- **TailwindCSS** for styling
- **Radix UI** for components

### Key Design Patterns
- **DAG Execution** - Topological sorting for correct execution order
- **Incremental Updates** - Only re-execute changed nodes and downstream
- **Hash-Based Caching** - Automatic result caching with invalidation
- **Type-Safe Ports** - Strongly typed connections between nodes
- **Plugin Architecture** - Easy extension with custom nodes

---

## ğŸ“Š Example Workflow

### Classification Pipeline

1. **Generate Synthetic Data** (1000 samples, 5 features, 3 classes)
2. **Train/Test Split** (80/20 split)
3. **Random Forest Classifier** (100 estimators)
4. **2D Scatter Plot** (visualize predictions)

This workflow:
- Generates synthetic classification data
- Splits it into training and testing sets
- Trains a Random Forest model
- Visualizes the predictions

**Execution time:** ~2 seconds  
**Cache enabled:** Subsequent runs with same parameters are instant

---

## ğŸ”§ Development

### Adding Custom Nodes

```python
from backend.core.registry import register_node, NodeExecutor
from backend.core.types import NodeSpec, PortSpec, ParamSpec

@register_node
class MyCustomNode(NodeExecutor):
    def __init__(self):
        super().__init__(NodeSpec(
            type="custom.my_node",
            label="My Node",
            category="custom",
            description="Does something cool",
            inputs=[...],
            outputs=[...],
            params=[...]
        ))
    
    async def run(self, context):
        # Your logic here
        return NodeResult(outputs={...})
```

See `docs/PLUGIN_DEVELOPMENT.md` for full guide.

### Testing

```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test
```

---

## ğŸ“ˆ Performance

- **Node Execution Overhead:** < 100ms
- **Cache Hit Time:** < 10ms
- **UI Frame Rate:** 60 FPS
- **Workflow Load:** < 1s for 100 nodes
- **Dataset Support:** Up to 10M rows with Arrow/Parquet

---

## ğŸ” Security & Privacy

- âœ… **No Cloud Dependencies** - Everything runs locally
- âœ… **No Telemetry** - No data collection or tracking
- âœ… **Sandboxed File Access** - User must explicitly grant permissions
- âœ… **No Arbitrary Code Execution** - Safe plugin system

---

## ğŸ›£ï¸ Roadmap

### v0.2.0 (Next Release)
- [ ] Undo/redo functionality
- [ ] Workflow templates library
- [ ] Auto-save
- [ ] More ML algorithms (XGBoost, LightGBM)
- [ ] Time series nodes
- [ ] SQL query node

### v0.3.0 (Future)
- [ ] Real-time collaboration
- [ ] GPU acceleration
- [ ] Distributed execution
- [ ] Cloud sync (optional)
- [ ] Mobile companion app

---

## ğŸ“š Documentation

- **README.md** - Project overview
- **GETTING_STARTED.md** - Installation and basic usage
- **docs/API.md** - Backend API reference
- **docs/ARCHITECTURE.md** - System design and architecture
- **docs/PLUGIN_DEVELOPMENT.md** - Creating custom nodes

---

## ğŸ¤ Contributing

Contributions welcome! Areas for contribution:

1. **New Nodes** - Add data sources, transformations, or ML algorithms
2. **UI Improvements** - Enhance user experience
3. **Documentation** - Improve guides and examples
4. **Bug Fixes** - Report and fix issues
5. **Performance** - Optimize execution and rendering

---

## ğŸ“ License

MIT License - See LICENSE file for details

---

## ğŸ™ Acknowledgments

Built with:
- FastAPI
- React
- Tauri
- React Flow
- pandas
- scikit-learn
- Plotly
- TailwindCSS

---

## ğŸ“ Support

- **Documentation:** `docs/`
- **Examples:** `examples/`
- **Issues:** GitHub Issues
- **Discussions:** GitHub Discussions

---

## ğŸ“ Educational Use

Perfect for:
- **Data Science Education** - Visual, interactive learning
- **Prototyping** - Quick ML pipeline experimentation
- **Teaching** - Demonstrate data workflows
- **Research** - Reproducible analysis pipelines

---

## âš¡ Performance Tips

1. **Use Caching** - Nodes cache automatically; leverage this for iterative work
2. **Set Global Seed** - Ensures reproducibility across runs
3. **Sample Large Datasets** - Use sampling for exploration, full data for final runs
4. **Incremental Execution** - Only changed nodes re-execute
5. **Monitor Cache Size** - Clear cache periodically if disk space is limited

---

## ğŸ› Known Limitations

- Maximum recommended dataset size: 10M rows
- Tauri requires Rust toolchain for building
- Some ML algorithms may be slow on large datasets
- 3D plots can be slow with > 100k points

---

## ğŸ“Š Technical Specifications

**Backend:**
- Language: Python 3.10+
- Framework: FastAPI 0.104+
- Data: pandas 2.1+, numpy 1.26+
- ML: scikit-learn 1.3+
- Viz: plotly 5.18+

**Frontend:**
- Language: TypeScript 5.3+
- Framework: React 18.2+
- Desktop: Tauri 1.5+
- Canvas: React Flow 11.10+
- State: Zustand 4.4+

**Communication:**
- Protocol: HTTP REST
- Format: JSON + Arrow/Feather
- Port: 8765 (backend), 1420 (frontend)

---

## ğŸ¯ Project Status

**Current Version:** 0.1.0  
**Status:** MVP Complete  
**Stability:** Alpha  
**Production Ready:** No (development/educational use)

---

## ğŸš€ Next Steps

1. **Try the Examples** - Load `examples/classification_example.flow.json`
2. **Build Your First Workflow** - Start with synthetic data â†’ plot
3. **Explore Nodes** - Try different transformations and algorithms
4. **Create Custom Nodes** - Extend with your own logic
5. **Share Workflows** - Export and share `.flow.json` files

---

**Happy Data Flowing! ğŸŒŠğŸ“Š**
